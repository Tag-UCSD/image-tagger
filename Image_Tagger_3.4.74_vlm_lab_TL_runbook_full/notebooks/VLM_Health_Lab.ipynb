{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83e\uddea VLM Health Lab (Colab) \u2013 Image Tagger 3.4.74_vlm_lab_notebook_TL_runbook\n",
        "\n",
        "This notebook gives you an **anti-gravity, ephemeral lab** for the Image Tagger project.\n",
        "\n",
        "It is designed to:\n",
        "- unpack a copy of the Image Tagger repo,\n",
        "- set up a small database and a tiny synthetic image set,\n",
        "- run the **science pipeline** in stub mode (no real API keys needed),\n",
        "- and then run the **VLM Health** variance audit on the results.\n",
        "\n",
        "## Benefits vs Costs\n",
        "\n",
        "**Benefits (TRACK B \u2013 Science Notebook):**\n",
        "- Works on most machines with a browser and a Google account.\n",
        "- No Docker, no local Postgres install.\n",
        "- Good for *short, self-contained experiments* and demos.\n",
        "- Lets you inspect how the VLM health scripts behave on a toy dataset.\n",
        "\n",
        "**Costs / tradeoffs:**\n",
        "- The environment is **ephemeral**:\n",
        "  - when the Colab runtime disconnects or you close the tab,\n",
        "    everything under `/content` is **lost**.\n",
        "  - only files you explicitly **save to Google Drive** or **download**\n",
        "    will persist.\n",
        "- Performance is limited; this is not for large-scale runs.\n",
        "- If the repo layout changes, you may need to adjust a path or two.\n",
        "\n",
        "## Relationship to the Full App (TRACK A)\n",
        "\n",
        "- The **Full App (TRACK A)** runs via Docker (locally, Codespaces, or a VM).\n",
        "  - It is **persistent**: data and settings survive restarts.\n",
        "  - It is ideal for multi-week projects and full tagging workflows\n",
        "    with Workbench and Explorer.\n",
        "- This notebook is **ephemeral** and **minimal**:\n",
        "  - it focuses on the **science + VLM health** parts only.\n",
        "  - use it when students cannot run Docker or when you want\n",
        "    a light-weight lab exercise.\n",
        "\n",
        "Before using this notebook in class, instructors and TAs should read:\n",
        "\n",
        "- `docs/ops/Cloud_AntiGravity_Quickstart.md`\n",
        "- `docs/ops/Student_Quickstart_v3.4.73.md`\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "setup_env"
      },
      "source": [
        "# @title \ud83d\udce6 Step 1: Setup \"Anti-Gravity\" Environment\n",
        "# @markdown This cell installs Python dependencies and a lightweight PostgreSQL database\n",
        "# @markdown directly in this notebook. **Run it once at the start.**\n",
        "import os\n",
        "\n",
        "print(\"\u2b07\ufe0f Installing Python libraries...\")\n",
        "!pip install -q fastapi uvicorn sqlalchemy psycopg2-binary pydantic pydantic-settings\n",
        "!pip install -q openai anthropic pandas numpy scipy scikit-image requests opencv-python-headless\n",
        "\n",
        "print(\"\ud83d\udc18 Installing PostgreSQL (this may take a minute)...\")\n",
        "!sudo apt-get -y -qq update\n",
        "!sudo apt-get -y -qq install postgresql\n",
        "\n",
        "print(\"\ud83d\udd27 Starting PostgreSQL service...\")\n",
        "!sudo service postgresql start\n",
        "\n",
        "print(\"\ud83d\udee0\ufe0f Configuring database user and schema...\")\n",
        "!sudo -u postgres psql -c \"CREATE USER tagger WITH PASSWORD 'tagger_pass';\" || echo \"User may already exist.\"\n",
        "!sudo -u postgres psql -c \"CREATE DATABASE image_tagger_v3 OWNER tagger;\" || echo \"DB may already exist.\"\n",
        "\n",
        "os.environ['DATABASE_URL'] = \"postgresql://tagger:tagger_pass@localhost:5432/image_tagger_v3\"\n",
        "os.environ['IMAGE_STORAGE_ROOT'] = \"/content/data_store\"\n",
        "\n",
        "print(\"\u2705 Environment Ready. If you see errors above, read them carefully before continuing.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upload_zip"
      },
      "source": [
        "# @title \ud83d\udcc2 Step 2: Upload the Image Tagger ZIP\n",
        "# @markdown 1. Run this cell.\n",
        "# @markdown 2. Click **\"Choose Files\"** when prompted.\n",
        "# @markdown 3. Upload the Image Tagger repo zip your instructor gave you\n",
        "# @markdown    (for example: `Image_Tagger_3.4.74_vlm_lab_TL_runbook_full.zip` or later).\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "uploaded = files.upload()\n",
        "if not uploaded:\n",
        "    raise RuntimeError(\"No file uploaded. Please upload the Image Tagger zip.\")\n",
        "filename = next(iter(uploaded))\n",
        "print(f\"\ud83d\udce6 Unpacking {filename}...\")\n",
        "\n",
        "os.makedirs(\"/content/repo\", exist_ok=True)\n",
        "with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/repo\")\n",
        "\n",
        "os.chdir(\"/content/repo\")\n",
        "print(\"\u2705 Repo unpacked in /content/repo and set as current directory.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seed_db"
      },
      "source": [
        "# @title \ud83c\udf31 Step 3: Seed Database & Generate Toy Images\n",
        "# @markdown This step:\n",
        "# @markdown - creates database tables,\n",
        "# @markdown - seeds basic configuration (if seed scripts are present),\n",
        "# @markdown - generates a few synthetic \"architectural\" images.\n",
        "import sys\n",
        "import numpy as np\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "\n",
        "# Ensure Python can find backend modules\n",
        "sys.path.append(\"/content/repo\")\n",
        "\n",
        "print(\"\ud83d\udd04 Creating database tables...\")\n",
        "from backend.database.core import engine, Base, SessionLocal\n",
        "from backend.models import *  # noqa: F401,F403\n",
        "Base.metadata.create_all(bind=engine)\n",
        "\n",
        "print(\"\ud83c\udf31 Seeding configs & attributes (if seed scripts are present)...\")\n",
        "try:\n",
        "    !python3 backend/scripts/seed_tool_configs.py\n",
        "except Exception as e:\n",
        "    print(\"   -> seed_tool_configs.py not found or failed:\", e)\n",
        "try:\n",
        "    !python3 backend/scripts/seed_attributes.py\n",
        "except Exception as e:\n",
        "    print(\"   -> seed_attributes.py not found or failed:\", e)\n",
        "\n",
        "print(\"\ud83d\uddbc\ufe0f Generating synthetic images...\")\n",
        "data_store = Path(os.environ['IMAGE_STORAGE_ROOT'])\n",
        "data_store.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "from backend.models.assets import Image\n",
        "\n",
        "with SessionLocal() as db:\n",
        "    for i in range(1, 6):\n",
        "        img = np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)\n",
        "        # Draw a central \"building\" rectangle\n",
        "        cv2.rectangle(img, (100, 100), (400, 400), (200, 200, 200), -1)\n",
        "        p = data_store / f\"toy_arch_{i}.jpg\"\n",
        "        cv2.imwrite(str(p), img)\n",
        "\n",
        "        db_img = Image(filename=p.name, storage_path=str(p))\n",
        "        db.add(db_img)\n",
        "        db.commit()\n",
        "        print(f\"   -> Created {p.name} (ID: {db_img.id})\")\n",
        "\n",
        "print(\"\u2705 Toy data ready.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "run_science"
      },
      "source": [
        "# @title \ud83d\udd2c Step 4: Run Science Pipeline (Stub VLM)\n",
        "# @markdown This runs the Image Tagger science pipeline on the toy images.\n",
        "# @markdown If no real VLM keys are set, it should fall back to a stub/neutral engine,\n",
        "# @markdown which is fine for testing the *plumbing*.\n",
        "import asyncio\n",
        "from backend.database.core import SessionLocal\n",
        "from backend.models.assets import Image\n",
        "from backend.science.pipeline import SciencePipeline\n",
        "\n",
        "print(\"\ud83e\uddea Running science pipeline on toy images...\")\n",
        "\n",
        "async def run_pipeline():\n",
        "    db = SessionLocal()\n",
        "    try:\n",
        "        pipeline = SciencePipeline(db)\n",
        "        images = db.query(Image).all()\n",
        "        for img in images:\n",
        "            print(f\"   Analyzing Image {img.id} ({img.filename})...\")\n",
        "            await pipeline.process_image(img.id)\n",
        "    finally:\n",
        "        db.close()\n",
        "\n",
        "await run_pipeline()\n",
        "print(\"\u2705 Science pipeline complete.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "run_audit"
      },
      "source": [
        "# @title \ud83d\udcca Step 5: Run VLM Health Variance Audit\n",
        "# @markdown This uses the `scripts/audit_vlm_variance.py` helper script from the repo\n",
        "# @markdown to compute simple variance statistics over VLM outputs.\n",
        "# @markdown\n",
        "# @markdown **Note:** The exact output paths may differ slightly by version.\n",
        "# @markdown If no CSV appears, inspect the script output and adjust the glob pattern.\n",
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "print(\"\ud83d\udcc9 Running VLM variance audit...\")\n",
        "!python3 scripts/audit_vlm_variance.py\n",
        "\n",
        "candidates = []\n",
        "candidates.extend(glob.glob(\"reports/vlm_health/*/vlm_variance_audit.csv\"))\n",
        "candidates.extend(glob.glob(\"reports/vlm_health/*/variance_audit.csv\"))\n",
        "\n",
        "if not candidates:\n",
        "    print(\"\u274c No variance audit CSV found.\")\n",
        "    print(\"   Please check the output of audit_vlm_variance.py above and adjust the path if needed.\")\n",
        "else:\n",
        "    path = sorted(candidates)[-1]\n",
        "    print(f\"\ud83d\udcc4 Found variance audit CSV: {path}\")\n",
        "    df = pd.read_csv(path)\n",
        "    display(df.head())\n",
        "    print(f\"Rows: {len(df)}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}